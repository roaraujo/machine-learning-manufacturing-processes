{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.stats import ks_2samp\n",
    "from IPython.display import Image\n",
    "\n",
    "import shap\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, LeaveOneOut, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from plot_learning import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn_rvm import EMRVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, RandomizedSearchCV\n",
    "from sklearn.metrics  import average_precision_score, make_scorer, roc_curve,f1_score, precision_score, recall_score, fbeta_score, auc, roc_auc_score, accuracy_score, confusion_matrix, classification_report,precision_recall_curve\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Continuous, Categorical, Integer\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "X_train_2 = pd.read_csv(\"train_2.csv\", sep = \",\")\n",
    "X_test_2 = pd.read_csv(\"test_2.csv\", sep = \",\")\n",
    "\n",
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train_2[['Y']]\n",
    "y_test = X_test_2[['Y']]\n",
    "\n",
    "\n",
    "X_train = X_train_2[['CONICITY', 'RFV','RRO', 'H2RFV',\n",
    "        'PLY','LFV', 'CAPSPLICE']]\n",
    "\n",
    "X_test = X_test_2[['CONICITY', 'RFV','RRO', 'H2RFV',\n",
    "        'PLY','LFV', 'CAPSPLICE']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.Y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_print(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_df = pd.DataFrame(cm)                      \n",
    "    plt.figure(figsize=(8,6))  \n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_pred))  \n",
    "\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred, multi_class = 'ovr', average=None)\n",
    "    gini = 2*roc_auc -1\n",
    "    print(\"Gini: \",gini)\n",
    "    print(\"ROC AUC:: \",roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve_cross_validation(df, title, ylim=None, train_sizes=np.linspace(1, 64, 64)):\n",
    "    \"\"\"Generate a simple plot of the test and training learning curve\"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Score\")\n",
    "\n",
    "    train_scores_mean = df.mean_train_score\n",
    "    train_scores_std = df.std_train_score\n",
    "    test_scores_mean = df.mean_test_score\n",
    "    test_scores_std = df.std_test_score\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 21)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=2)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "DT_search_space = {\n",
    "        \"criterion\": Categorical([\"gini\", \"entropy\"]),\n",
    "        \"max_depth\": Integer(4, 8),\n",
    "        \"max_features\": Categorical(['auto', 'sqrt','log2']), \n",
    "        \"min_samples_leaf\": Integer(2, 10),\n",
    "        \"min_samples_split\": Integer(8, 20),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_GA_search = GASearchCV(estimator=DT, param_grid=DT_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "inicio = time.time()\n",
    "DT_GA_search.fit(X_train, y_train) # callback=on_step will print score after each iteration\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(DT_GA_search.best_score_)\n",
    "DT_best = DT_GA_search.best_estimator_\n",
    "print(DT_GA_search.best_estimator_)\n",
    "print(DT_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(DT_best, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(random_state = 23)\n",
    "# cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=2)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "RF_search_space = {\"bootstrap\": Categorical([True]), # values for boostrap can be either True or False\n",
    "        \"criterion\": Categorical([\"gini\", \"entropy\"]),\n",
    "        \"max_depth\": Integer(4, 8),\n",
    "        \"max_features\": Categorical(['auto', 'sqrt','log2']), \n",
    "        \"min_samples_leaf\": Integer(2, 10),\n",
    "        \"min_samples_split\": Integer(8, 30),\n",
    "        \"n_estimators\": Integer(5, 20)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://sklearn-genetic-opt.readthedocs.io/en/stable/api/gasearchcv.html\n",
    "\n",
    "RF_GA_search = GASearchCV(estimator=RF, param_grid=RF_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "inicio = time.time()\n",
    "RF_GA_search.fit(X_train, y_train) # callback=on_step will print score after each iteration\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(RF_GA_search.best_score_)\n",
    "RF_best = RF_GA_search.best_estimator_\n",
    "print(RF_GA_search.best_estimator_)\n",
    "print(RF_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic.plots import plot_fitness_evolution\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot = plot_fitness_evolution(RF_GA_search, metric=\"fitness\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(RF_GA_search.cv_results_).sort_values(by = 'rank_test_score')\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv2 = pd.DataFrame(RF_GA_search.cv_results_)\n",
    "results_cv2  = results_cv2[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']]\n",
    "# plot_learning_curve_cross_validation(results_cv2, \"RF learning curve - GASearchCV\")\n",
    "results_cv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_learning_curve(RF_best,\"Random Forest learning curves\",X_train, y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vot = './models/RF_best_GA_v2.sav'\n",
    "joblib.dump(RF_best, filename_vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(RF_best, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = SVC(random_state = 261, probability=True)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "SVM_search_space = {\n",
    "        'gamma': Continuous(0.01, 10), \n",
    "        'kernel': Categorical(['rbf', 'poly', 'sigmoid']), \n",
    "        'C': Continuous(0.1, 10)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_GA_search = GASearchCV(estimator=SVM, param_grid=SVM_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "SVM_GA_search.fit(X_train, y_train) # callback=on_step will print score after each iteration\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(SVM_GA_search.best_score_)\n",
    "SVM_best = SVM_GA_search.best_estimator_\n",
    "print(SVM_GA_search.best_estimator_)\n",
    "print(SVM_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(SVM_GA_search.cv_results_).sort_values(by = 'rank_test_score')\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv2 = pd.DataFrame(SVM_GA_search.cv_results_)\n",
    "results_cv2  = results_cv2[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']]\n",
    "results_cv2.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_learning_curve(SVM_best,\"SVM learning curves\",X_train,y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vot = './models/SVM_best_GA_v2.sav'\n",
    "joblib.dump(SVM_best, filename_vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(SVM_best, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state = 26)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "MLP_search_space = {\n",
    "    # 'hidden_layer_sizes': [(100,), (60,70,50), (70,80,60)],\n",
    "    'activation':  Categorical(['tanh', 'relu', 'logistic', 'identity']),\n",
    "    'solver':  Categorical(['sgd', 'adam']),\n",
    "    'alpha': Continuous(0.001, 0.1),\n",
    "    'learning_rate': Categorical(['adaptive', 'constant', 'invscaling']),\n",
    "    'learning_rate_init': Continuous(0.001, 0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP_model = RandomizedSearchCV(estimator= MLP, param_distributions = MLP_search_space, cv=cv, scoring=\"accuracy\")\n",
    "MLP_GA_search = GASearchCV(estimator=MLP, param_grid=MLP_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "inicio = time.time()\n",
    "MLP_GA_search.fit(X_train, y_train)\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(MLP_GA_search.best_score_)\n",
    "MLP_best = MLP_GA_search.best_estimator_\n",
    "print(MLP_GA_search.best_estimator_)\n",
    "print(MLP_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv2 = pd.DataFrame(MLP_GA_search.cv_results_)\n",
    "results_cv2  = results_cv2[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']]\n",
    "# plot_learning_curve_cross_validation(results_cv2, \"MLP learning curve - GASearchCV\")\n",
    "results_cv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_learning_curve(MLP_best,\"Multi-layer Perceptron learning curves\", X_train, y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vot = './models/MLP_best_GA_v2.sav'\n",
    "joblib.dump(MLP_best, filename_vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(MLP_best, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM = GradientBoostingClassifier(random_state=31)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "\n",
    "GBM_search_space = {\n",
    "\n",
    "        'max_depth': Integer(4, 8),\n",
    "        'loss': Categorical(['deviance']),\n",
    "        'learning_rate' : Continuous(0.001, 0.01) , \n",
    "        'n_estimators': Integer(5, 20),\n",
    "        'criterion': Categorical(['friedman_mse', 'mse']),\n",
    "        \"max_features\": Categorical(['auto', 'sqrt','log2']), \n",
    "        \"min_samples_leaf\": Integer(2, 8),\n",
    "        \"min_samples_split\": Integer(5, 25)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_GA_search = GASearchCV(estimator=GBM, param_grid=GBM_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "GBM_GA_search.fit(X_train, y_train) # callback=on_step will print score after each iteration\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(GBM_GA_search.best_score_)\n",
    "GBM_best = GBM_GA_search.best_estimator_\n",
    "print(GBM_GA_search.best_estimator_)\n",
    "print(GBM_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM_GA_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv2 = pd.DataFrame(GBM_GA_search.cv_results_)\n",
    "results_cv2  = results_cv2[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']]\n",
    "results_cv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_learning_curve(GBM_best,\"GBM learning curves\",X_train, y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vot = './models/GBM_best_GA_v2.sav'\n",
    "joblib.dump(GBM_best, filename_vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(GBM_best, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM = LGBMClassifier(random_state=32)\n",
    "# cv = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=0)\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "LGBM_search_space = {\n",
    "        'num_iterations': Integer(25, 50),\n",
    "        'learning_rate' : Continuous(0.001, 0.01) , \n",
    "        'n_estimators': Integer(5, 40),\n",
    "        'boosting_type': Categorical(['goss']),\n",
    "        'objective': Categorical(['binary']),\n",
    "        \"num_leaves\": Integer(5, 20),\n",
    "        \"min_child_samples\": Integer(2, 10), \n",
    "        \"reg_alpha\": Continuous(0.01, 0.5)\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_GA_search = GASearchCV(estimator=LGBM, param_grid=LGBM_search_space, return_train_score = True, \n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=cv,\n",
    "                                    population_size=10,\n",
    "                                    generations=5,\n",
    "                                    tournament_size=3,\n",
    "                                    elitism=True,\n",
    "                                    crossover_probability=0.8,\n",
    "                                    mutation_probability=0.1,\n",
    "                                    criteria='max',\n",
    "                                    algorithm='eaMuPlusLambda',\n",
    "                                    keep_top_k=4)\n",
    "\n",
    "inicio = time.time()\n",
    "LGBM_GA_search.fit(X_train, y_train) # callback=on_step will print score after each iteration\n",
    "fim = time.time()\n",
    "print(\"time train\")\n",
    "print(fim - inicio)\n",
    "print(\"Acc\")\n",
    "print(LGBM_GA_search.best_score_)\n",
    "LGBM_best = LGBM_GA_search.best_estimator_\n",
    "print(LGBM_GA_search.best_estimator_)\n",
    "print(LGBM_GA_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LGBM_GA_search.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv2 = pd.DataFrame(LGBM_GA_search.cv_results_)\n",
    "results_cv2  = results_cv2[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score']]\n",
    "results_cv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = plot_learning_curve(LGBM_best,\"LGBM learning curves\",X_train, y_train,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_vot = './models/LGBM_best_GA_v2.sav'\n",
    "joblib.dump(LGBM_best, filename_vot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_and_print(LGBM_best, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(model, l):\n",
    "    #fit logistic regression model and plot ROC curve\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred)\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_pred), 4)\n",
    "    plt.plot(fpr,tpr,label=l+ \" , AUC=\"+str(auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['RF', 'SVM', \"MLP\", \"GBM\", \"LGBM\"]\n",
    "models = [RF_best, SVM_best, MLP_best, GBM_best, LGBM_best]\n",
    "\n",
    "#set up plotting area\n",
    "plt.figure(0).clf()\n",
    "\n",
    "for i, j in enumerate(models):\n",
    "\n",
    "    plot_roc(j, labels[i])\n",
    "\n",
    "\n",
    "#add legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('artigo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "77b285dce526106f0619df26edb004dd0a55300a7a7a7660bd0bf561a0915729"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
